{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Pigs_49651_960_540_500f\n",
      "\n",
      "Feature: DataRGB\n",
      "Class Distribution:\n",
      "16\n",
      "17    0.089299\n",
      "16    0.088561\n",
      "10    0.085609\n",
      "1     0.077860\n",
      "11    0.073432\n",
      "2     0.066790\n",
      "12    0.063469\n",
      "9     0.060148\n",
      "18    0.053875\n",
      "7     0.050923\n",
      "6     0.049077\n",
      "13    0.047601\n",
      "5     0.047232\n",
      "4     0.030627\n",
      "14    0.028782\n",
      "8     0.018819\n",
      "20    0.014760\n",
      "15    0.014022\n",
      "0     0.013653\n",
      "19    0.013284\n",
      "3     0.007380\n",
      "21    0.004797\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add these lines at the beginning of your code to define the parameter grid for KNN and SVM classifiers\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 21, 2),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(video_name):\n",
    "    data_files = [\n",
    "        f\"{video_name}_DataRGB.csv\",\n",
    "        f\"{video_name}_DataHOG.csv\",\n",
    "        f\"{video_name}_DataH10.csv\",\n",
    "        f\"{video_name}_DataLBP.csv\",\n",
    "    ]\n",
    "    labels_file = f\"{video_name}_Labels.csv\"\n",
    "\n",
    "    data = [pd.read_csv(file) for file in data_files]\n",
    "    labels = pd.read_csv(labels_file)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def split_data(data, labels, training_size):\n",
    "    X_train = data.iloc[:training_size, :]\n",
    "    X_test = data.iloc[training_size:, :]\n",
    "    y_train = labels.iloc[:training_size, :]\n",
    "    y_test = labels.iloc[training_size:, :]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def class_distribution(y_train):\n",
    "    return y_train.value_counts(normalize=True)\n",
    "\n",
    "def compare_results(video_name, feature_name, results_df):\n",
    "    ground_truth_file = f\"{video_name}_Results.csv\"\n",
    "    ground_truth_results = pd.read_csv(ground_truth_file, header=None, sep=\",\")\n",
    "\n",
    "    mean_ground_truth = ground_truth_results.mean(axis=0)\n",
    "    std_ground_truth = ground_truth_results.std(axis=0)\n",
    "\n",
    "    print(f\"\\nGround truth results for {video_name} using {feature_name} features:\")\n",
    "    print(f\"Mean: {mean_ground_truth.values[0]:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_ground_truth.values[0]:.4f}\")\n",
    "\n",
    "    mean_code_results = results_df['Accuracy'].mean()\n",
    "    std_code_results = results_df['Accuracy'].std()\n",
    "\n",
    "    print(f\"\\nCode results for {video_name} using {feature_name} features:\")\n",
    "    print(f\"Mean: {mean_code_results:.4f}\")\n",
    "    print(f\"Standard Deviation: {std_code_results:.4f}\")\n",
    "\n",
    "def largest_prior_classifier(y_train):\n",
    "    return y_train.value_counts().idxmax()\n",
    "\n",
    "def predict_largest_prior(y_train, X_test):\n",
    "    largest_prior = largest_prior_classifier(y_train)\n",
    "    return np.full(X_test.shape[0], largest_prior)\n",
    "def train_and_evaluate_classifiers(X_train, X_test, y_train, y_test):\n",
    "    classifiers = [\n",
    "        ('Largest Prior', None),\n",
    "        ('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "        ('3-nn', KNeighborsClassifier(n_neighbors=3)),\n",
    "        ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "        ('SVM', SVC(random_state=42)),\n",
    "        ('Bagging', BaggingClassifier(random_state=42)),\n",
    "        ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "        ('KNN (tuned)', knn_tuned),\n",
    "        ('SVM (tuned)', svm_tuned)\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    largest_prior_accuracy = y_test.value_counts(normalize=True).max()\n",
    "    results.append({'Classifier': 'Largest Prior', 'Accuracy': largest_prior_accuracy})\n",
    "\n",
    "    for name, classifier in classifiers[1:]:\n",
    "        if name == 'Ensemble':\n",
    "            y_pred = ensemble_voting_classifier(classifiers[1:], X_train, y_train, X_test)\n",
    "        else:\n",
    "            classifier.fit(X_train, y_train.values.ravel())\n",
    "            y_pred = classifier.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append({'Classifier': name, 'Accuracy': accuracy})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components=0.95):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(classifier, param_grid, X_train, y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=cv, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y.values.ravel())\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_voting_classifier(classifiers, X_train, y_train, X_test):\n",
    "    voting_clf = VotingClassifier(estimators=classifiers, voting='hard', n_jobs=-1)\n",
    "    voting_clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "# Main loop\n",
    "if __name__ == \"__main__\":\n",
    "    video_info = {\n",
    "        'Pigs_49651_960_540_500f': 2710,\n",
    "        'Koi_5652_952_540': 916,\n",
    "        'Pigeons_8234_1280_720': 2268,\n",
    "        'Pigeons_4927_960_540_600f': 1574,\n",
    "        'Pigeons_29033_960_540_300f': 2148\n",
    "    }\n",
    "\n",
    "    feature_names = ['DataRGB', 'DataHOG', 'DataH10', 'DataLBP']\n",
    "\n",
    "    for video_name, training_size in video_info.items():\n",
    "        print(f'Processing {video_name}')\n",
    "        data, labels = load_data(video_name)\n",
    "        for i, feature_data in enumerate(data):\n",
    "            feature_name = feature_names[i]\n",
    "            print(f'\\nFeature: {feature_name}')\n",
    "            X_train_temp, X_test_temp, y_train_temp, y_test_temp = split_data(feature_data, labels, training_size)\n",
    "            X_train_scaled, X_test_scaled = preprocess_data(X_train_temp, X_test_temp)\n",
    "\n",
    "            # Apply PCA\n",
    "            X_train_pca, X_test_pca = apply_pca(X_train_scaled, X_test_scaled)\n",
    "\n",
    "            # Check class distribution\n",
    "            print(f'Class Distribution:\\n{class_distribution(y_train_temp)}\\n')\n",
    "\n",
    "            knn_tuned = hyperparameter_tuning(KNeighborsClassifier(), knn_params, X_train_pca, y_train_temp)\n",
    "            svm_tuned = hyperparameter_tuning(SVC(probability=True), svm_params, X_train_pca, y_train_temp)\n",
    "\n",
    "            # Perform cross-validation\n",
    "            cv_scores_knn = cross_val_score(knn_tuned, X_train_pca, y_train_temp.values.ravel(), cv=StratifiedKFold(n_splits=5))\n",
    "            cv_scores_svm = cross_val_score(svm_tuned, X_train_pca, y_train_temp.values.ravel(), cv=StratifiedKFold(n_splits=5))\n",
    "            print(f\"Cross-validation scores for KNN: {cv_scores_knn}\")\n",
    "            print(f\"Cross-validation scores for SVM: {cv_scores_svm}\")\n",
    "\n",
    "            # Evaluate classifiers\n",
    "            results_df = train_and_evaluate_classifiers(X_train_pca, X_test_pca, y_train_temp, y_test_temp)\n",
    "            print(results_df)\n",
    "\n",
    "            # Compare results with ground truth\n",
    "            compare_results(video_name, feature_name, results_df)\n",
    "\n",
    "        print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
